{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e51010da",
   "metadata": {},
   "source": [
    "<center><h1>Assignment 1</h1></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a6e59d",
   "metadata": {},
   "source": [
    "<center><h3>Text generation using N-gram</h2><center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1489ee68",
   "metadata": {},
   "source": [
    "<center>Saleh Mohammed Al saeed</center>\n",
    "\n",
    "<center>441014299</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dbd4a87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "\n",
    "import os\n",
    "import random\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import PlaintextCorpusReader\n",
    "from nltk.util import ngrams\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90322087",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['بسم', 'الله', 'الرحمن', 'الرحيم', 'الحمد', 'لله', ...]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load A corpus into string variable because the data are huge it will take time to predict\n",
    "corpus_path = os.getcwd() + '/Corpus/A'\n",
    "corpus = PlaintextCorpusReader(corpus_path, '.*\\.txt')\n",
    "words = corpus.words()\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ccbe4117",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed words: 5,999,258\n",
      "Total of cleaned words: 22,734,267\n"
     ]
    }
   ],
   "source": [
    "# Preprocess text\n",
    "# stop_words = set(stopwords.words('arabic')) \n",
    "# Not needed because result will be not accurate\n",
    "\n",
    "words_cleaned = [word for word in words if not word in ['*', '_', '\"', '.', '،', ',','-','«', '(', ')', '{', '}', '[', ']', ':', '?', '؟'] and not word.isnumeric()]\n",
    "\n",
    "\n",
    "print(f\"Removed words: {(len(words) - len(words_cleaned)):,}\")\n",
    "print(f\"Total of cleaned words: {len(words_cleaned):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71b2d7ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the value of n:  6\n"
     ]
    }
   ],
   "source": [
    "# Ask the user to define value n\n",
    "n = int(input(\"Enter the value of n: \"))\n",
    "\n",
    "while(n > 6 or n < 2):\n",
    "    print(\"n must be between 2 and 6\")\n",
    "    n = int(input(\"Enter the value of n: \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91c6cb54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate N-grams\n",
    "ngrams_list = ngrams(words_cleaned, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c66c811",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate frequency of N-grams\n",
    "ngrams_freq = FreqDist(ngrams_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b25c14e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort the frequent sentence with descending order to become faster to find\n",
    "ngrams_freq_sorted = sorted(ngrams_freq.items(), key= lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b81ba2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trigram check is for matching the sentence with the trigram and find the best match\n",
    "def trigram_check(start_slice: int, n_gram: int, trigram: tuple, sentence: str):\n",
    "    \n",
    "    context = sentence.split()\n",
    "    if len(context) >= n_gram:\n",
    "        context = context[-n_gram:]\n",
    "        \n",
    "    if list(trigram[-n_gram:]) == context[-n_gram:]:\n",
    "        return [False, random.choice(words_cleaned)]\n",
    "    \n",
    "    if(context[0] in trigram and trigram.index(context[0]) == start_slice and context[0] != trigram[len(trigram) - 1]):\n",
    "        for i in range(start_slice, start_slice + n_gram):\n",
    "            if(i < len(context) and context[i] != trigram[i]):\n",
    "                return [False, random.choice(words_cleaned)]\n",
    "        \n",
    "        try:\n",
    "            return [True, trigram[trigram.index(context[len(context) - 1]) + 1]]\n",
    "        except:\n",
    "            return [False, random.choice(words_cleaned)]\n",
    "    return [False, random.choice(words_cleaned)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b1d8fc29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'العالمين'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict next word based on the words in sentence\n",
    "def predict_nextword(sentence: str):\n",
    "    next_word = None\n",
    "    \n",
    "    for trigram, freq in ngrams_freq_sorted:\n",
    "        for i in range(n):\n",
    "            next_word = trigram_check(i, n, trigram, sentence)\n",
    "            if next_word[0]:\n",
    "                return next_word[1]\n",
    "            \n",
    "    return next_word[1]\n",
    "\n",
    "# Try the function\n",
    "predict_nextword(\"الحمد لله رب\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "017ebf4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to generate output sentence\n",
    "def generate_sentence(seed_word: str, num_of_words: int):\n",
    "    sentence = \"\" + seed_word.strip() + \" \"\n",
    "    for i in range(num_of_words - len(seed_word.split())):\n",
    "        sentence += predict_nextword(sentence) + \" \"\n",
    "        \n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d6fe6860",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter a word:  جعلناكم\n",
      "Enter the number of word want to generate:  6\n"
     ]
    }
   ],
   "source": [
    "# Ask the user to enter first word to generate sentence\n",
    "seed_word = input(\"Enter a word: \")\n",
    "num_of_words = int(input(\"Enter the number of word want to generate: \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a72859ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'جعلناكم أمة وسطا لتكونوا شهداء على '"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Question1: Test the function\n",
    "generate_sentence(seed_word, num_of_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "91644d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question2: the 10 high frequent (trigram) in the corpus\n",
    "\n",
    "# reload the whole corpus\n",
    "corpus_path = os.getcwd() + '/Corpus/'\n",
    "corpus = PlaintextCorpusReader(corpus_path, '.*\\.txt')\n",
    "words = corpus.words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f937d018",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frequent n-gram and the most common n-grams\n",
    "ngrams_list = ngrams(words, n)\n",
    "ngrams_freq = FreqDist(ngrams_list)\n",
    "most_common_trigram = ngrams_freq.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "524cce24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('رسول', 'الله', 'صلى', 'الله', 'عليه', 'وسلم'): 83177\n",
      "('.', '.', '.', '.', '.', '.'): 33407\n",
      "('الله', 'صلى', 'الله', 'عليه', 'وسلم', ':'): 16009\n",
      "('-', 'صلى', 'الله', 'عليه', 'وسلم', '-'): 15115\n",
      "('عن', 'النبي', 'صلى', 'الله', 'عليه', 'وسلم'): 13075\n",
      "('صلى', 'الله', 'عليه', 'وسلم', ':', '«'): 12112\n",
      "('قال', 'رسول', 'الله', 'صلى', 'الله', 'عليه'): 11949\n",
      "('الله', 'صلى', 'الله', 'عليه', 'وسلم', '،'): 9120\n",
      "(':', 'قال', 'رسول', 'الله', 'صلى', 'الله'): 8998\n",
      "('__________', '[', 'تعليق', 'مصطفى', 'البغا', ']'): 8115\n"
     ]
    }
   ],
   "source": [
    "# Printing the n-grams before removing the symbols\n",
    "for trigram, count in most_common_trigram:\n",
    "    print(f\"{trigram}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "983632db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean the trigram\n",
    "symbols = ['-[', '__________', '*', '/','_', '\"', '.', '،', ',','-','«', '(', ')', '{', '}', '[', ']', ':', '?', '؟']\n",
    "words_cleaned = [word for word in words if not word in symbols and not word.isnumeric()]\n",
    "\n",
    "# n-grams after removing the symbols\n",
    "ngrams_list = ngrams(words_cleaned, n)\n",
    "ngrams_freq = FreqDist(ngrams_list)\n",
    "most_common_trigram = ngrams_freq.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "95440751",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('رسول', 'الله', 'صلى', 'الله', 'عليه', 'وسلم'): 91285\n",
      "('عن', 'النبي', 'صلى', 'الله', 'عليه', 'وسلم'): 14549\n",
      "('قال', 'رسول', 'الله', 'صلى', 'الله', 'عليه'): 12701\n",
      "('أن', 'رسول', 'الله', 'صلى', 'الله', 'عليه'): 9062\n",
      "('قال', 'قال', 'رسول', 'الله', 'صلى', 'الله'): 8847\n",
      "('النبي', 'صلى', 'الله', 'عليه', 'وسلم', 'قال'): 7631\n",
      "('أن', 'النبي', 'صلى', 'الله', 'عليه', 'وسلم'): 7178\n",
      "('الله', 'صلى', 'الله', 'عليه', 'وسلم', 'قال'): 6873\n",
      "('عن', 'ابن', 'أبي', 'نجيح', 'عن', 'مجاهد'): 6348\n",
      "('عن', 'رسول', 'الله', 'صلى', 'الله', 'عليه'): 4890\n"
     ]
    }
   ],
   "source": [
    "# Printing the n-grams After removing the symbols\n",
    "for trigram, count in most_common_trigram:\n",
    "    print(f\"{trigram}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3ad57b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the most common to a text file\n",
    "with open('most_common_trigram.txt', 'w', encoding='utf-8') as f:\n",
    "    for trigram, freq in most_common_trigram:\n",
    "        f.write(' '.join(trigram) + '\\t' + str(freq) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ad06d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
